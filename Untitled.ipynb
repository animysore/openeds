{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adishrao/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py:886: MatplotlibDeprecationWarning: \n",
      "examples.directory is deprecated; in the future, examples will be found relative to the 'datapath' directory.\n",
      "  \"found relative to the 'datapath' directory.\".format(key))\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import keras, sys, time, warnings\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = '/Users/adishrao/Desktop/FB/fbdata/'\n",
    "img_dir_org = basedir\n",
    "image_paths = open(basedir+'/images.txt').read().split()\n",
    "label_paths = open(basedir+'/labels.txt').read().split()\n",
    "\n",
    "labelled_image_paths = []\n",
    "\n",
    "for lbl in label_paths:\n",
    "    folder, label_file = lbl.split('/')\n",
    "    image_file = label_file[6:-4]\n",
    "    image_path = '/'.join([folder,image_file]) + '.png'\n",
    "    \n",
    "    if image_path not in image_paths: \n",
    "        print('Error! We seem to have made a wrong image path: ', image_path)\n",
    "    \n",
    "    labelled_image_paths.append(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = sorted(label_paths)\n",
    "images_train = sorted(labelled_image_paths)\n",
    "dir_train = '/Users/adishrao/Desktop/FB/fbdata/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR. Check folder organisation\n",
      "i 0\n"
     ]
    }
   ],
   "source": [
    "width, height = 160,96\n",
    "nc = 3\n",
    "DATASIZE = 400\n",
    "\n",
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "ik=0\n",
    "\n",
    "\n",
    "for img_path, lbl_path in list(zip(images_train,labels_train))[:DATASIZE]:\n",
    "    if img_path[:8] != lbl_path[:8]:\n",
    "        print('ERROR. Check folder organisation')\n",
    "        break\n",
    "        \n",
    "for img_path, lbl_path in list(zip(images_train,labels_train))[:]:\n",
    "    try:\n",
    "        # load image and label, resize, append\n",
    "        img = cv2.imread(dir_train + img_path)\n",
    "        img = np.float32(img) / 255 \n",
    "        X_train.append(img)\n",
    "\n",
    "        lbl = np.load(dir_train + lbl_path)\n",
    "        for i in lbl:\n",
    "            for index, item in enumerate(i):\n",
    "                if item == 3:\n",
    "                    i[index] = 2\n",
    "        seg = np.zeros((  height , width  , nc ))\n",
    "        for c in range(nc):\n",
    "            seg[:, :, c] = (lbl==c).astype(int)\n",
    "        Y_train.append(seg)\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        print(img_path,lbl_path)\n",
    "        ik+=1\n",
    "print(\"i\",ik)\n",
    "X_train, Y_train = np.array(X_train) , np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_input = Input(shape=(96,160 , 3 ))\n",
    "\n",
    "conv1_1 = Conv2D(32, (3, 3), activation='relu', padding='same')(img_input)\n",
    "pool1 = MaxPooling2D((2, 2))(conv1_1)\n",
    "\n",
    "conv2_1 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)     #Make 3,3 (?)\n",
    "pool2 = MaxPooling2D((2, 2))(conv2_1)\n",
    "\n",
    "#decode\n",
    "conv3_1 = Conv2D(32, (3, 3), activation='relu', padding='same')(pool2)\n",
    "conv3_2 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv3_1)\n",
    "conv3_3 = Add()([conv3_2,conv3_1])\n",
    "\n",
    "conv3_4 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv3_3)\n",
    "conv3_5 = Add()([conv3_2,conv3_4])\n",
    "\n",
    "conv3_6 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv3_5)\n",
    "conv3_7 = Add()([conv3_6,conv3_4])\n",
    "\n",
    "\n",
    "up1 = concatenate([Conv2DTranspose(6, (2,2), strides=(2,2))(conv3_7), conv2_1], axis=-1)\n",
    "conv4_1 = Conv2D(64, (3, 3), activation='relu', padding='same')(up1)\n",
    "\n",
    "conv4_2 = Add()([conv4_1,conv2_1])\n",
    "\n",
    "up2 = concatenate([Conv2DTranspose(6, (2,2), strides=(2,2))(conv4_2), conv1_1], axis=-1)\n",
    "conv5_1 = Conv2D(32, (3, 3), activation='relu', padding='same')(up2)\n",
    "\n",
    "\n",
    "conv5_2 = Add()([conv5_1,conv1_1])\n",
    "\n",
    "out = Conv2D( nc, (1, 1) , padding='same')(conv5_2)\n",
    "o = (Activation('softmax'))(out)\n",
    "\n",
    "model = Model(img_input, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 96, 160, 3)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 96, 160, 32)  896         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 48, 80, 32)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 48, 80, 64)   18496       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 24, 40, 64)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 24, 40, 32)   18464       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 24, 40, 32)   9248        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 24, 40, 32)   0           conv2d_4[0][0]                   \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 24, 40, 32)   9248        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 24, 40, 32)   0           conv2d_4[0][0]                   \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 24, 40, 32)   9248        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 24, 40, 32)   0           conv2d_6[0][0]                   \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 48, 80, 6)    774         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 48, 80, 70)   0           conv2d_transpose_1[0][0]         \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 48, 80, 64)   40384       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 48, 80, 64)   0           conv2d_7[0][0]                   \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 96, 160, 6)   1542        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 96, 160, 38)  0           conv2d_transpose_2[0][0]         \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 96, 160, 32)  10976       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 96, 160, 32)  0           conv2d_8[0][0]                   \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 96, 160, 3)   99          add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 96, 160, 3)   0           conv2d_9[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 119,375\n",
      "Trainable params: 119,375\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1203 samples, validate on 402 samples\n",
      "Epoch 1/30\n",
      "1203/1203 [==============================] - 279s 232ms/step - loss: 0.6557 - acc: 0.8264 - val_loss: 0.5237 - val_acc: 0.8616\n",
      "Epoch 2/30\n",
      "1203/1203 [==============================] - 278s 231ms/step - loss: 0.4536 - acc: 0.8591 - val_loss: 0.3432 - val_acc: 0.8616\n",
      "Epoch 3/30\n",
      "1203/1203 [==============================] - 277s 231ms/step - loss: 0.2989 - acc: 0.8816 - val_loss: 0.2473 - val_acc: 0.9039\n",
      "Epoch 4/30\n",
      "1203/1203 [==============================] - 324s 270ms/step - loss: 0.2517 - acc: 0.9031 - val_loss: 0.2417 - val_acc: 0.9056\n",
      "Epoch 5/30\n",
      "1203/1203 [==============================] - 276s 230ms/step - loss: 0.2230 - acc: 0.9136 - val_loss: 0.2118 - val_acc: 0.9156\n",
      "Epoch 6/30\n",
      "1203/1203 [==============================] - 278s 231ms/step - loss: 0.2014 - acc: 0.9205 - val_loss: 0.1971 - val_acc: 0.9192\n",
      "Epoch 7/30\n",
      "1203/1203 [==============================] - 307s 255ms/step - loss: 0.1839 - acc: 0.9272 - val_loss: 0.1712 - val_acc: 0.9326\n",
      "Epoch 8/30\n",
      "1024/1203 [========================>.....] - ETA: 41s - loss: 0.1739 - acc: 0.9312"
     ]
    }
   ],
   "source": [
    "hist1 = model.fit(X_train,Y_train,\n",
    "                  validation_split=0.25,\n",
    "                  batch_size=32,epochs=30,verbose=1)\n",
    "model.save('fbmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in ['loss', 'val_loss']:\n",
    "    plt.plot(hist1.history[key],label=key)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need to fix below code for fb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_val)\n",
    "y_predi = np.argmax(y_pred, axis=3)\n",
    "y_testi = np.argmax(Y_val, axis=3)\n",
    "print(y_testi.shape,y_predi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_dup = np.copy(y_predi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IoU(Yi,y_predi):\n",
    "    ## mean Intersection over Union\n",
    "    ## Mean IoU = TP/(FN + TP + FP)\n",
    "\n",
    "    IoUs = []\n",
    "    Nclass = int(np.max(Yi)) + 1\n",
    "    for c in range(Nclass):\n",
    "        TP = np.sum( (Yi == c)&(y_predi==c) )\n",
    "        FP = np.sum( (Yi != c)&(y_predi==c) )\n",
    "        FN = np.sum( (Yi == c)&(y_predi != c)) \n",
    "        IoU = TP/float(TP + FP + FN)\n",
    "        print(\"class {:02.0f}: #TP={:6.0f}, #FP={:6.0f}, #FN={:5.0f}, IoU={:4.3f}\".format(c,TP,FP,FN,IoU))\n",
    "        IoUs.append(IoU)\n",
    "    mIoU = np.mean(IoUs)\n",
    "    print(\"_________________\")\n",
    "    print(\"Mean IoU: {:4.3f}\".format(mIoU))\n",
    "    \n",
    "IoU(y_testi,y_predi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (96,160)\n",
    "n_classes= 4\n",
    "\n",
    "for i in range(10):\n",
    "    img_is  = (X_val[i])*(255.0/2)\n",
    "    seg = y_predi[i]\n",
    "    segtest = y_testi[i]\n",
    "\n",
    "    fig = plt.figure(figsize=(10,30))    \n",
    "    ax = fig.add_subplot(1,3,1)\n",
    "    ax.imshow(img_is/255.0)\n",
    "    ax.set_title(\"original\")\n",
    "    \n",
    "    ax = fig.add_subplot(1,3,2)\n",
    "    ax.imshow(seg)\n",
    "    ax.set_title(\"predicted class\")\n",
    "    \n",
    "    ax = fig.add_subplot(1,3,3)\n",
    "    ax.imshow(segtest)\n",
    "    ax.set_title(\"true class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_row_bounds(X):\n",
    "    for i,r in enumerate(X):\n",
    "        if 2 in r:\n",
    "            break\n",
    "    rowstart  = i\n",
    "    for i,r in enumerate(X[::-1]):\n",
    "        if 2 in r:\n",
    "            break\n",
    "    rowend  = 159 - i\n",
    "    \n",
    "    return (rowstart, rowend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in y_predi:\n",
    "    rowstart, rowend = find_row_bounds(img)\n",
    "    if rowstart-15 >= 0:\n",
    "        img[:(rowstart-15)].fill(0)\n",
    "\n",
    "    if rowend+15 <= 159:\n",
    "        img[(rowend+15):].fill(0)\n",
    "\n",
    "plt.imshow(y_predi[1508])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IoU(Yi,y_predi):\n",
    "    ## mean Intersection over Union\n",
    "    ## Mean IoU = TP/(FN + TP + FP)\n",
    "\n",
    "    IoUs = []\n",
    "    Nclass = int(np.max(Yi)) + 1\n",
    "    for c in range(Nclass):\n",
    "        TP = np.sum( (Yi == c)&(y_predi==c) )\n",
    "        FP = np.sum( (Yi != c)&(y_predi==c) )\n",
    "        FN = np.sum( (Yi == c)&(y_predi != c)) \n",
    "        IoU = TP/float(TP + FP + FN)\n",
    "        print(\"class {:02.0f}: #TP={:6.0f}, #FP={:6.0f}, #FN={:5.0f}, IoU={:4.3f}\".format(c,TP,FP,FN,IoU))\n",
    "        IoUs.append(IoU)\n",
    "    mIoU = np.mean(IoUs)\n",
    "    print(\"_________________\")\n",
    "    print(\"Mean IoU: {:4.3f}\".format(mIoU))\n",
    "    \n",
    "IoU(y_testi,y_predi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mean IoU: 0.946"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage.measurements import label\n",
    " \n",
    "structure = np.ones((3, 3), dtype=np.int)\n",
    " \n",
    "tempi = np.copy(y_predi)\n",
    " \n",
    "for pred in tempi:\n",
    "    pred_copy = np.copy(pred)\n",
    "    pred_copy[ pred_copy > 0 ] = 1\n",
    " \n",
    "    labeled, ncomponents = label(pred_copy, structure)\n",
    "    unique, counts = np.unique(labeled, return_counts=True)\n",
    "    unique = list(unique)\n",
    "    counts = list(counts)\n",
    "    unique.pop(0)\n",
    "    counts.pop(0)\n",
    "    largest = counts.index(max(counts))\n",
    "    pred[[labeled!=(largest+1)]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IoU(Yi,y_predi):\n",
    "    ## mean Intersection over Union\n",
    "    ## Mean IoU = TP/(FN + TP + FP)\n",
    "\n",
    "    IoUs = []\n",
    "    Nclass = int(np.max(Yi)) + 1\n",
    "    for c in range(Nclass):\n",
    "        TP = np.sum( (Yi == c)&(y_predi==c) )\n",
    "        FP = np.sum( (Yi != c)&(y_predi==c) )\n",
    "        FN = np.sum( (Yi == c)&(y_predi != c)) \n",
    "        IoU = TP/float(TP + FP + FN)\n",
    "        print(\"class {:02.0f}: #TP={:6.0f}, #FP={:6.0f}, #FN={:5.0f}, IoU={:4.3f}\".format(c,TP,FP,FN,IoU))\n",
    "        IoUs.append(IoU)\n",
    "    mIoU = np.mean(IoUs)\n",
    "    print(\"_________________\")\n",
    "    print(\"Mean IoU: {:4.3f}\".format(mIoU))\n",
    "    \n",
    "IoU(y_testi,tempi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mean IoU: 0.949\n",
    "    \n",
    "submitted: 0.946"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_image = load_model('rotated_images.h5')\n",
    "model_eyes = load_model('eyes.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height = 160, 96\n",
    "X = []\n",
    "Y = []\n",
    "img = cv2.imread('Openedsdata2020/openEDS2020-SparseSegmentation/participant/S_0/21.png')\n",
    "img = cv2.resize(img, (width, height)) \n",
    "img = np.float32(img) / 255\n",
    "X.append(img)\n",
    "img = cv2.imread('Openedsdata2020/openEDS2020-SparseSegmentation/participant/S_0/23.png')\n",
    "img = cv2.resize(img, (width, height)) \n",
    "img = np.float32(img) / 255\n",
    "X.append(img)\n",
    "lbl = np.load('Openedsdata2020/openEDS2020-SparseSegmentation/participant/S_0/label_21.npy')\n",
    "Y.append(lbl)\n",
    "lbl = np.load('Openedsdata2020/openEDS2020-SparseSegmentation/participant/S_0/label_23.npy')\n",
    "Y.append(lbl)\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_predict = model_image.predict(X)\n",
    "initial_predict = np.argmax(initial_predict, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage.measurements import label\n",
    " \n",
    "structure = np.ones((3, 3), dtype=np.int)\n",
    "  \n",
    "for pred in initial_predict:\n",
    "    pred_copy = np.copy(pred)\n",
    "    pred_copy[ pred_copy > 0 ] = 1\n",
    " \n",
    "    labeled, ncomponents = label(pred_copy, structure)\n",
    "    unique, counts = np.unique(labeled, return_counts=True)\n",
    "    unique = list(unique)\n",
    "    counts = list(counts)\n",
    "    unique.pop(0)\n",
    "    counts.pop(0)\n",
    "    largest = counts.index(max(counts))\n",
    "    pred[[labeled!=(largest+1)]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_middle(X):\n",
    "    for i,r in enumerate(X):\n",
    "        if 3 in r:\n",
    "            break\n",
    "    rowstart  = i\n",
    "    for i,r in enumerate(X[::-1]):\n",
    "        if 3 in r:\n",
    "            break\n",
    "    rowend  = 95 - i\n",
    "    \n",
    "    for j in range(160):\n",
    "        if 3 in X[:,j]:\n",
    "            break\n",
    "    colstart = j\n",
    "    colend = 0\n",
    "    for r in X:\n",
    "        for index,j in enumerate(r):\n",
    "            if j == 3:\n",
    "                if index>colend:\n",
    "                    colend = index\n",
    "    return (rowstart,rowend,colstart,colend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_list = []\n",
    "X_eyes = []\n",
    "i = 0\n",
    "for predict,img in zip(initial_predict,X):\n",
    "    rowstart,rowend,colstart,colend = find_middle(predict)\n",
    "    midY, midX = int((rowstart+rowend)/2), int((colstart+colend)/2)\n",
    "    if midX <16:\n",
    "        midX = 16\n",
    "    if midX > (159-16):\n",
    "        midX = 159 - 16\n",
    "    if midY <16:\n",
    "        midY = 16\n",
    "    if midY > (95-16):\n",
    "        midY = 95 - 16\n",
    "    new_X = img[(midY-16):(midY+16),(midX-16):(midX+16)]\n",
    "    if new_X.shape != (32,32,3):\n",
    "        print(i,new_X.shape)\n",
    "    X_eyes.append(new_X)\n",
    "    i+=1\n",
    "    xy_list.append([midX,midY])\n",
    "X_eyes = np.array(X_eyes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(initial_predict[0])\n",
    "print(xy_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_eye_predict = model_eyes.predict(X_eyes)\n",
    "initial_eye_predict = np.argmax(initial_eye_predict, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(initial_eye_predict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (predict,eye,(midx,midy)) in zip(initial_predict,initial_eye_predict,xy_list):\n",
    "    i,j=0,0\n",
    "    for row in range(midy-16,midy+16):\n",
    "        j=0\n",
    "        for col in range(midx-16,midx+16):\n",
    "            if eye[i][j]==1:\n",
    "                predict[row][col] = 3 \n",
    "            j+=1\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(initial_predict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
